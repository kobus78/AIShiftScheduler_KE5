{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# policy\n",
    "> Agent | Policy\n",
    "- order: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "len(RESOURCE_TYPES)=3\n",
      "['Manager', 'AssistMngr', 'RetailAssoc']\n",
      "\n",
      "len(TYPES)=13\n",
      "['Manager', 'AssistMngr', 'AssistMngr', 'RetailAssoc', 'RetailAssoc', 'RetailAssoc', 'RetailAssoc', 'RetailAssoc', 'RetailAssoc', 'RetailAssoc', 'RetailAssoc', 'RetailAssoc', 'RetailAssoc']\n",
      "len(aNAMES)=13\n",
      "['Manager_Matt', 'AssistMngr_Mike', 'AssistMngr_Tanner', 'RetailAssoc_Jake', 'RetailAssoc_James', 'RetailAssoc_Jane', 'RetailAssoc_John', 'RetailAssoc_Jim', 'RetailAssoc_Jenny', 'RetailAssoc_Jeremy', 'RetailAssoc_Judy', 'RetailAssoc_Julie', 'RetailAssoc_Jeffrey']\n",
      "\n",
      "len(bNAMES)=3\n",
      "['Manager', 'AssistMngr', 'RetailAssoc']\n",
      "\n",
      "len(abNAMES)=13\n",
      "['Manager_Matt___Manager', 'AssistMngr_Mike___AssistMngr', 'AssistMngr_Tanner___AssistMngr', 'RetailAssoc_Jake___RetailAssoc', 'RetailAssoc_James___RetailAssoc', 'RetailAssoc_Jane___RetailAssoc', 'RetailAssoc_John___RetailAssoc', 'RetailAssoc_Jim___RetailAssoc', 'RetailAssoc_Jenny___RetailAssoc', 'RetailAssoc_Jeremy___RetailAssoc', 'RetailAssoc_Judy___RetailAssoc', 'RetailAssoc_Julie___RetailAssoc', 'RetailAssoc_Jeffrey___RetailAssoc']\n",
      "\n",
      "len(thNAMES)=5\n",
      "thNAMES=['thCumSlots', 'thSickProb', 'thCumMerits', 'thContSlots', 'thSelect']\n",
      "\n",
      "SIM_MU_D={'Manager': 4, 'AssistMngr': 2, 'RetailAssoc': 2}\n",
      "\n",
      "SIM_EVENT_TIME_D={'Manager': None, 'AssistMngr': None, 'RetailAssoc': None}\n",
      "\n",
      "SIM_MU_DELTA_D={'Manager': None, 'AssistMngr': None, 'RetailAssoc': None}\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from collections import namedtuple, defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "from copy import copy\n",
    "# import time\n",
    "# import math\n",
    "# from pprint import pprint\n",
    "## !pip install -U \"ray\"\n",
    "import ray\n",
    "# import json\n",
    "import random\n",
    "\n",
    "from fastcore.basics import patch\n",
    "# from AIShiftScheduler_KE5.config import *\n",
    "import AIShiftScheduler_KE5.config as cf\n",
    "# from AIShiftScheduler_KE5.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.3'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze | grep pandas\n",
    "# !pip freeze|grep openpyxl\n",
    "# !pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U ray==2.8.1\n",
    "# !pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@ray.remote\n",
    "def parallel_run_grid_sample_paths(pol, theta, piName, L, T):\n",
    "# def parallel_run_grid_sample_paths(pol, theta, piName):    \n",
    "    CcumIomega__lI = []\n",
    "    record = []\n",
    "    for l in range(1, L + 1): ## for each sample-path\n",
    "        print(f'\\t%%% {l=}')\n",
    "        from AIShiftScheduler_KE5.model import Model ## here, else circular import for Model & Policy\n",
    "        M = Model()\n",
    "        pol.model = M\n",
    "        record_l = [piName, theta, l]\n",
    "        dt = pd.to_datetime(cf.START_DATE_TIME)\n",
    "        dt_delta = pd.Timedelta(cf.DATE_TIME_DELTA)\n",
    "        for t in range(T): ## for each transition/step\n",
    "            ## print(f'\\t%%% {t=}')\n",
    "            ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "            ## Lookup new (today's) decision\n",
    "            getattr(pol, piName)(t, dt, pol.model.S_t, pol.model.x_t, theta)\n",
    "\n",
    "            ## sit in post-decision state until end of cycle (evening),\n",
    "            ## waiting for exog info to arrive\n",
    "\n",
    "            ## Change from today to tomorrow\n",
    "            ## S_t, Ccum, x_t = self.model.step(t, x_t, theta)\n",
    "            record_t = pol.model.step(t, dt, theta)\n",
    "            ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "            record.append(record_l + record_t)\n",
    "            dt = dt + dt_delta\n",
    "        CcumIomega__lI.append(pol.model.Ccum) ##just above (SDAM-eq2.9)\n",
    "    return (CcumIomega__lI, record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClass(int): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def func(self: MyClass, a): return self + a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = MyClass(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.func(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Policy(): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def __init__(self:Policy, model):\n",
    "    self.model = model\n",
    "    self.Policy = namedtuple('Policy', cf.piNAMES) ## 'class'\n",
    "    self.Theta = namedtuple('Theta', cf.thNAMES) ## 'class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def build_policy(self:Policy, info):\n",
    "    return self.Policy(*[info[pin] for pin in cf.piNAMES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def build_theta(self:Policy, info):\n",
    "    return self.Theta(*[info[thn] for thn in cf.thNAMES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def X__Alloc(self:Policy, t, dt, S_t, x_t, theta):\n",
    "    ## print(f\"\\n..... Policy.X__Alloc() .....\\n{t=}, {dt=}\")\n",
    "    demandsToService = []\n",
    "    for rt in cf.RESOURCE_TYPES:\n",
    "      number = S_t['D_t'].loc[\n",
    "        S_t['D_t']['Type']==rt,\n",
    "        ['DMax_t']\n",
    "      ].squeeze()\n",
    "      demandsToService.append((rt, round(number))) ##whole number of resources\n",
    "    ## print(f\"demandsToService:\\n{demandsToService}\")\n",
    "    for demand in demandsToService:\n",
    "      resourceType, number = demand; ##print(f'{resourceType=}, {number=}')\n",
    "      candidates_avail = S_t['R_t'].loc[\n",
    "        (S_t['R_t']['Type'] == resourceType) & \\\n",
    "        (S_t['R_t']['RAvail_t'] == 1) & \\\n",
    "        (S_t['R_t']['RComplete_t'] == 0) & \\\n",
    "        (S_t['R_t']['RCumSlots_t'] < cf.MAX_DAILY_SLOT_RUN),\n",
    "        ## (S_t['R_t']['RUtil_t'] < cf.GOV_UTIL_THRESH) & \\\n",
    "        ['ResourceId', 'Type', 'RAvail_t', 'RComplete_t', 'RCumSlots_t', 'RCumMerits_t']\n",
    "      ]; ## print(f'candidates_avail BEFORE arrangement for selection=\\n{candidates_avail}')\n",
    "      ## merge with previous allocations to enhance contiguous allocs\n",
    "      candidates = \\\n",
    "        S_t['xAlloc_t_1']\\\n",
    "        .merge(candidates_avail, left_index=True, right_index=True)\\\n",
    "        .sort_values(by='Allocd_t', ascending=False)\n",
    "      candidates.rename(columns={'Allocd_t': 'Allocd_t_1'}, inplace=True)\n",
    "      if len(candidates) > 0 and number > 0:\n",
    "        if theta.thSelect == 'random':\n",
    "          candidates = candidates.sample(frac = 1) ## shuffle rows; now opt/non have different x's\n",
    "          candidates = candidates.sort_values(by=['Allocd_t_1'], ascending=False)\n",
    "        elif theta.thSelect == 'ranked_CumMerits':\n",
    "          candidates = candidates.sort_values(by=['Allocd_t_1','RCumMerits_t'], ascending=False)\n",
    "        else:\n",
    "          print(f'ERROR: Invalid value for theta.thSelect: {theta.thSelect}')\n",
    "        ## print(f'candidates AFTER arrangement for selection=\\n{candidates}')\n",
    "        if len(candidates) >= number:\n",
    "          allocs = candidates.iloc[0:number, :]; ##print(f'allocs=\\n{allocs}') #pick first 'number' avails\n",
    "        elif len(candidates) < number:\n",
    "          ##print('%%% NOT ENOUGH candidates')\n",
    "          allocs = copy(candidates); ##print(f'allocs=\\n{allocs}') ##pick all candidates\n",
    "          unallocated_demands = number - len(candidates) ##unmet demands\n",
    "          ## self.model.Ccum -= unallocated_demands\n",
    "          self.model.Ucum_Total += unallocated_demands\n",
    "          self.model.Ucum[resourceType] += unallocated_demands\n",
    "        if len(allocs) == 0:\n",
    "          x_t['xAlloc_t'].loc[\n",
    "            x_t['xAlloc_t']['Comb'].map(lambda e: e.split('_')[0]==resourceType),\n",
    "            ['Allocd_t']\n",
    "          ] = False\n",
    "        else:\n",
    "          x_t['xAlloc_t'].loc[ ##remove all allocs before adding new allocs\n",
    "            x_t['xAlloc_t']['Comb'].map(lambda e: e.split('_')[0]==resourceType),\n",
    "            ['Allocd_t']\n",
    "          ] = False\n",
    "          x_t['xAlloc_t'].loc[\n",
    "            x_t['xAlloc_t']['Comb'].apply(lambda x: x.split(\"_\")[1]).isin(allocs['ResourceId']),\n",
    "            ['Allocd_t']\n",
    "          ] = True\n",
    "          ## TODO: update utilizations\n",
    "        self.model.update_Ccum(t, dt, S_t, x_t, theta)\n",
    "      else:\n",
    "        ## print(f'%%% Shift has no resource for demand {demand}, or demand is 0.')\n",
    "        x_t['xAlloc_t'].loc[\n",
    "          x_t['xAlloc_t']['Comb'].map(lambda e: e.split('_')[0]==resourceType),\n",
    "          ['Allocd_t']\n",
    "        ] = False\n",
    "      ## print(f\"x_t['xAlloc_t']:\\n{x_t['xAlloc_t']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def run_grid_sample_paths(self:Policy, theta, piName, record, L, T):\n",
    "# def run_grid_sample_paths(self:Policy, theta, piName, record): !!!!!!!!!!!!!!!!!!!!!!!    \n",
    "    CcumIomega__lI = []\n",
    "    for l in range(1, L + 1): ## for each sample-path\n",
    "      print(f'\\t%%% {l=}')\n",
    "      from AIShiftScheduler_KE5.model import Model ## here, else circular import for Model & Policy\n",
    "      M = Model()\n",
    "      ## P = Policy(M) ## SG, NO!, overwrite existing global P\n",
    "      self.model = M\n",
    "      record_l = [piName, theta, l]\n",
    "      dt = pd.to_datetime(cf.START_DATE_TIME)\n",
    "      dt_delta = pd.Timedelta(cf.DATE_TIME_DELTA)\n",
    "      for t in range(T): ## for each transition/step\n",
    "        ## print(f'\\t%%% {t=}')\n",
    "        ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "        ## Lookup new (today's) decision\n",
    "        getattr(self, piName)(t, dt, self.model.S_t, self.model.x_t, theta)\n",
    "\n",
    "        ## sit in post-decision state until end of cycle (evening),\n",
    "        ## waiting for exog info to arrive\n",
    "\n",
    "        ## Change from today to tomorrow\n",
    "        ## S_t, Ccum, x_t = self.model.step(t, x_t, theta)\n",
    "        record_t = self.model.step(t, dt, theta)\n",
    "        ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "        record.append(record_l + record_t)\n",
    "        dt = dt + dt_delta\n",
    "      CcumIomega__lI.append(self.model.Ccum) ##just above (SDAM-eq2.9)\n",
    "    return CcumIomega__lI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def perform_grid_search_sample_paths(self:Policy, piName, thetas, L, T):\n",
    "# def perform_grid_search_sample_paths(self:Policy, piName, thetas): !!!!!!!!!!!!!!!!!!!    \n",
    "    Cbarcum = defaultdict(float)\n",
    "    Ctilcum = defaultdict(float)\n",
    "    expCbarcum = defaultdict(float)\n",
    "    expCtilcum = defaultdict(float)\n",
    "    numThetas = len(thetas)\n",
    "    record = []\n",
    "    print(f'{numThetas=:,}')\n",
    "    nth = 1\n",
    "    i = 0; print(f'... printing every {nth}th theta (if considered) ...')\n",
    "    for theta in thetas:\n",
    "      if True: ##in case relationships between thetas can be exploited\n",
    "        ## a dict cannot be used as a key, so we define theta_key, e.g.\n",
    "        ## theta_key = ((168.0, 72.0), (200.0, 90.0)):\n",
    "        ## theta_key = tuple(tuple(itm.values()) for itm in theta)\n",
    "        theta_key = theta ##if theta is not a dict\n",
    "\n",
    "        ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "        # CcumIomega__lI = self.run_grid_sample_paths(theta, piName, record) !!!!!!!!!!!!!!!\n",
    "        CcumIomega__lI = self.run_grid_sample_paths(theta, piName, record, L, T)  \n",
    "        ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "        Cbarcum_tmp = np.array(CcumIomega__lI).mean() #(SDAM-eq2.9)\n",
    "        Ctilcum_tmp = np.sum(np.square(np.array(CcumIomega__lI) - Cbarcum_tmp))/(L - 1)\n",
    "\n",
    "        Cbarcum[theta_key] = Cbarcum_tmp\n",
    "        Ctilcum[theta_key] = np.sqrt(Ctilcum_tmp/L)\n",
    "\n",
    "        expCbarcum_tmp = pd.Series(CcumIomega__lI).expanding().mean()\n",
    "        expCbarcum[theta_key] = expCbarcum_tmp\n",
    "\n",
    "        expCtilcum_tmp = pd.Series(CcumIomega__lI).expanding().std()\n",
    "        expCtilcum[theta_key] = expCtilcum_tmp\n",
    "        if i%nth == 0: print(f'{i:,}/{(numThetas-1):,}, {Cbarcum[theta_key]:,.0f}, {theta}')\n",
    "        i += 1\n",
    "      ##endif\n",
    "    best_theta = max(Cbarcum, key=Cbarcum.get)\n",
    "    worst_theta = min(Cbarcum, key=Cbarcum.get)\n",
    "\n",
    "    best_Cbarcum = Cbarcum[best_theta]\n",
    "    best_Ctilcum = Ctilcum[best_theta]\n",
    "\n",
    "    worst_Cbarcum = Cbarcum[worst_theta]\n",
    "    worst_Ctilcum = Ctilcum[worst_theta]\n",
    "\n",
    "    thetaStar_expCbarcum = expCbarcum[best_theta]\n",
    "    thetaStar_expCtilcum = expCtilcum[best_theta]\n",
    "    thetaStar_expCtilcum[0] = 0 ##set NaN to 0\n",
    "\n",
    "    ## best_theta_w_names = tuple((\n",
    "    #   ({\n",
    "    #     a1NAMES[0]: subvec[0],\n",
    "    #     a1NAMES[1]: subvec[1]\n",
    "    #   })) for subvec in best_theta)\n",
    "    ## best_theta_n = self.build_theta({'thAdj': best_theta_w_names[0]})\n",
    "    ## best_theta_n = self.build_theta({'thAdj1': best_theta_w_names[0], 'thAdj3': best_theta_w_names[1]})\n",
    "    ## print(f'best_theta_n:\\n{best_theta_n}\\n{best_Cbarcum=:.2f}\\n{best_Ctilcum=:.2f}')\n",
    "\n",
    "    ## worst_theta_w_names = tuple((\n",
    "    #   ({\n",
    "    #     a1NAMES[0]: subvec[0],\n",
    "    #     a1NAMES[1]: subvec[1]})) for subvec in worst_theta)\n",
    "    ## worst_theta_n = self.build_theta({'thAdj': worst_theta_w_names[0]})\n",
    "    ## worst_theta_n = self.build_theta({'thAdj1': worst_theta_w_names[0], 'thAdj3': worst_theta_w_names[1]})\n",
    "    ## print(f'worst_theta_n:\\n{worst_theta_n}\\n{worst_Cbarcum=:.2f}\\n{worst_Ctilcum=:.2f}')\n",
    "\n",
    "    return \\\n",
    "      thetaStar_expCbarcum, thetaStar_expCtilcum, \\\n",
    "      Cbarcum, Ctilcum, \\\n",
    "      best_theta, worst_theta, \\\n",
    "      best_Cbarcum, worst_Cbarcum, \\\n",
    "      best_Ctilcum, worst_Ctilcum, \\\n",
    "      record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def parallel_run_grid_sample_paths(...) is a function above this class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def parallel_perform_grid_search_sample_paths(self:Policy, piName, thetas, L, T):\n",
    "# def parallel_perform_grid_search_sample_paths(self:Policy, piName, thetas):    \n",
    "      Cbarcum = defaultdict(float)\n",
    "      Ctilcum = defaultdict(float)\n",
    "      expCbarcum = defaultdict(float)\n",
    "      expCtilcum = defaultdict(float)\n",
    "      numThetas = len(thetas)\n",
    "      record = []\n",
    "      print(f'{numThetas=:,}')\n",
    "      nth = 1\n",
    "      i = 0; print(f'... printing every {nth}th theta (if considered) ...')\n",
    "      \n",
    "      ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "      ## THIS BREAKS:\n",
    "      ## futures = [self.parallel_run_grid_sample_paths.remote(theta, piName) for theta in thetas]\n",
    "      # futures = [parallel_run_grid_sample_paths.remote(self, theta, piName) for theta in thetas] !!!!!!!\n",
    "      futures = [parallel_run_grid_sample_paths.remote(self, theta, piName, L, T) for theta in thetas]\n",
    "      result = ray.get(futures)\n",
    "      ## return result ##handy to debug\n",
    "      ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "      for j,theta in enumerate(thetas):\n",
    "          ## if True: ##in case relationships between thetas can be exploited\n",
    "          ## a dict cannot be used as a key, so we define theta_key, e.g.\n",
    "          ## theta_key = ((168.0, 72.0), (200.0, 90.0)):\n",
    "          ## theta_key = tuple(tuple(itm.values()) for itm in theta)\n",
    "          theta_key = theta ##if theta is not a dict\n",
    "\n",
    "          ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "          ## CcumIomega__lI = self.run_grid_sample_paths(theta, piName, record)\n",
    "          ## >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "\n",
    "          ## Cbarcum_tmp = np.array(CcumIomega__lI).mean() #(SDAM-eq2.9)\n",
    "          Cbarcum_tmp = np.array(result[j][0]).mean() #(SDAM-eq2.9)\n",
    "          ## Ctilcum_tmp = np.sum(np.square(np.array(CcumIomega__lI) - Cbarcum_tmp))/(L - 1)\n",
    "          Ctilcum_tmp = np.sum(np.square(np.array(result[j][0]) - Cbarcum_tmp))/(L - 1)\n",
    "\n",
    "          Cbarcum[theta_key] = Cbarcum_tmp\n",
    "          Ctilcum[theta_key] = np.sqrt(Ctilcum_tmp/L)\n",
    "\n",
    "          ## expCbarcum_tmp = pd.Series(CcumIomega__lI).expanding().mean()\n",
    "          expCbarcum_tmp = pd.Series(result[j][0]).expanding().mean()\n",
    "          expCbarcum[theta_key] = expCbarcum_tmp\n",
    "\n",
    "          ## expCtilcum_tmp = pd.Series(CcumIomega__lI).expanding().std()\n",
    "          expCtilcum_tmp = pd.Series(result[j][0]).expanding().std()\n",
    "          expCtilcum[theta_key] = expCtilcum_tmp\n",
    "          if i%nth == 0: print(f'{i:,}/{(numThetas-1):,}, {Cbarcum[theta_key]:,.0f}, {theta}')\n",
    "          i += 1\n",
    "          ##endif\n",
    "          next_th = result[j][1]\n",
    "          for e in next_th:\n",
    "              record.append(e)\n",
    "      best_theta = max(Cbarcum, key=Cbarcum.get)\n",
    "      worst_theta = min(Cbarcum, key=Cbarcum.get)\n",
    "\n",
    "      best_Cbarcum = Cbarcum[best_theta]\n",
    "      best_Ctilcum = Ctilcum[best_theta]\n",
    "\n",
    "      worst_Cbarcum = Cbarcum[worst_theta]\n",
    "      worst_Ctilcum = Ctilcum[worst_theta]\n",
    "\n",
    "      thetaStar_expCbarcum = expCbarcum[best_theta]\n",
    "      thetaStar_expCtilcum = expCtilcum[best_theta]\n",
    "      thetaStar_expCtilcum[0] = 0 ##set NaN to 0\n",
    "\n",
    "      return \\\n",
    "        thetaStar_expCbarcum, thetaStar_expCtilcum, \\\n",
    "        Cbarcum, Ctilcum, \\\n",
    "        best_theta, worst_theta, \\\n",
    "        best_Cbarcum, worst_Cbarcum, \\\n",
    "        best_Ctilcum, worst_Ctilcum, \\\n",
    "        record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "## EXAMPLE:\n",
    "## thetasA: Buy\n",
    "## thetasA_name: 'thBuy'\n",
    "## names: ELA\n",
    "## 1_1: 1 theta sub-vectors, each having 1 theta\n",
    "## thetas = grid_search_thetas_1_2(thetasBuy 'thBuy', CAR_TYPES)\n",
    "@patch\n",
    "def grid_search_thetas_1_1(self:Policy, thetasA, thetasA_name, names):\n",
    "    thetas = [\n",
    "    self.build_theta({thetasA_name: {names[0]: thA0}})\n",
    "    for thA0 in thetasA[names[0]]\n",
    "    ]\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "## EXAMPLE:\n",
    "## thetasA: Buy\n",
    "## thetasA_name: 'thBuy'\n",
    "## names: ELA, SON\n",
    "## 1_2: 1 theta sub-vectors, each having 2 thetas\n",
    "## thetas = grid_search_thetas_1_2(thetasBuy 'thBuy', CAR_TYPES)\n",
    "@patch\n",
    "def grid_search_thetas_1_2(self:Policy, thetasA, thetasA_name, names):\n",
    "    thetas = [\n",
    "    self.build_theta({thetasA_name: {names[0]: thA0, names[1]: thA1}})\n",
    "    for thA0 in thetasA[names[0]]\n",
    "      for thA1 in thetasA[names[1]]\n",
    "    ]\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE:\n",
    "## thetasA: Adj\n",
    "## thetasA_name: 'thAdj'\n",
    "## names: ELA, SON\n",
    "## 1_4: 1 theta sub-vectors, each having 4 thetas\n",
    "## thetas = grid_search_thetas_1_4(thetasBuy 'thAdj', bNAMES)\n",
    "@patch\n",
    "def grid_search_thetas_1_4(self:Policy, thetasA, thetasA_name, names):\n",
    "    thetas = [\n",
    "    self.build_theta({thetasA_name: {names[0]: thA0, names[1]: thA1, names[2]: thA2, names[3]: thA3}})\n",
    "    for thA0 in thetasA[names[0]]\n",
    "      for thA1 in thetasA[names[1]]\n",
    "        for thA2 in thetasA[names[2]]\n",
    "          for thA3 in thetasA[names[3]]\n",
    "    ]\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE:\n",
    "## thetasA: Buy\n",
    "## thetasB: Max\n",
    "## thetasA_name: 'thBuy'\n",
    "## thetasB_name: 'thMax'\n",
    "## names: ELA\n",
    "## 2_1: 2 theta sub-vectors, each having 1 theta\n",
    "## thetas = grid_search_thetas_2_1(thetasBuy, thetasMax, 'thBuy', 'thMax', CAR_TYPES)\n",
    "@patch\n",
    "def grid_search_thetas_2_1(self:Policy, thetasA, thetasB, thetasA_name, thetasB_name, names):\n",
    "    thetas = [\n",
    "    self.build_theta({thetasA_name: {names[0]: thA0}, thetasB_name: {names[0]: thB0}})\n",
    "    for thA0 in thetasA[names[0]]\n",
    "      for thB0 in thetasB[names[0]]\n",
    "    ]\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE:\n",
    "## thetasA: Buy\n",
    "## thetasB: Max\n",
    "## thetasA_name: 'thBuy'\n",
    "## thetasB_name: 'thMax'\n",
    "## names: ELA, SON\n",
    "## 2_2: 2 theta sub-vectors, each having 2 thetas\n",
    "## thetas = grid_search_thetas_4(thetasBuy, thetasMax, 'thBuy', 'thMax', CAR_TYPES)\n",
    "@patch\n",
    "def grid_search_thetas_2_2(self:Policy, thetasA, thetasB, thetasA_name, thetasB_name, names):\n",
    "    thetas = [\n",
    "    self.build_theta({thetasA_name: {names[0]: thA0, names[1]: thA1}, thetasB_name: {names[0]: thB0, names[1]: thB1}})\n",
    "    for thA0 in thetasA[names[0]]\n",
    "      for thA1 in thetasA[names[1]]\n",
    "        for thB0 in thetasB[names[0]]\n",
    "          for thB1 in thetasB[names[1]]\n",
    "    ]\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from AIShiftScheduler_KE5.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
