# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/08_evaluator.ipynb.

# %% auto 0
__all__ = ['do_evalu_opt', 'do_evalu_non']

# %% ../nbs/08_evaluator.ipynb 4
# from collections import namedtuple, defaultdict
# import numpy as np
import pandas as pd
# import matplotlib as mpl
# import matplotlib.pyplot as plt
from copy import copy
# import time
# import math
# from pprint import pprint
## !pip install -U "ray"
# import ray
# import json

import AIShiftScheduler_KE5.config as cf
from .model import *
from .policy import *

# %% ../nbs/08_evaluator.ipynb 8
pd.options.display.float_format = '{:,.4f}'.format
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
pd.set_option('display.max_colwidth', None)

# %% ../nbs/08_evaluator.ipynb 11
def do_evalu_opt(L, T, Best_theta_Alloc):
  # global DEM, MER, \
  # global ThetaStar_expCbarcum_Alloc_evalu_opt, ThetaStar_expCtilcum_Alloc_evalu_opt, \
  # Best_theta_Alloc_evalu_opt, Worst_theta_Alloc_evalu_opt, \
  # Record_Alloc_evalu_opt, Df_Alloc_evalu_opt, \
  # ThetaStar_expCbarcum_Alloc_evalu_non, ThetaStar_expCtilcum_Alloc_evalu_non, \
  # Best_theta_Alloc_evalu_non, Worst_theta_Alloc_evalu_non, \
  # Record_Alloc_evalu_non, Df_Alloc_evalu_non

  M = Model()
  P = Policy(M)
  ## DEM = DemandSimulator(seed=SEED_EVALU)
  ## MER = MeritSimulator(seed=SEED_EVALU)
  thetasOpt = []; thetasOpt.append(Best_theta_Alloc)
  # ThetaStar_expCbarcum_Alloc_evalu_opt, ThetaStar_expCtilcum_Alloc_evalu_opt, \
  # _, _, \
  # Best_theta_Alloc_evalu_opt, Worst_theta_Alloc_evalu_opt, \
  # _, _, \
  # _, _, \
  # Record_Alloc_evalu_opt = \
  #   P.perform_grid_search_sample_paths('X__Alloc', thetasOpt, L, T)
  return \
    P.perform_grid_search_sample_paths('X__Alloc', thetasOpt, L, T)
    
  # Df_Alloc_evalu_opt = pd.DataFrame.from_records(
  #     Record_Alloc_evalu_opt[:First_n_t], columns=Labels)
  # print(f'{ThetaStar_expCbarcum_Alloc_evalu_opt.iloc[-1]=:.2f}')

# %% ../nbs/08_evaluator.ipynb 12
def do_evalu_non(L, T, Worst_theta_Alloc):
  # global DEM, MER, \
  # global ThetaStar_expCbarcum_Alloc_evalu_opt, ThetaStar_expCtilcum_Alloc_evalu_opt, \
  # Best_theta_Alloc_evalu_opt, Worst_theta_Alloc_evalu_opt, \
  # Record_Alloc_evalu_opt, Df_Alloc_evalu_opt, \
  # ThetaStar_expCbarcum_Alloc_evalu_non, ThetaStar_expCtilcum_Alloc_evalu_non, \
  # Best_theta_Alloc_evalu_non, Worst_theta_Alloc_evalu_non, \
  # Record_Alloc_evalu_non, Df_Alloc_evalu_non

  M = Model()
  P = Policy(M)
  ## DEM = DemandSimulator(seed=SEED_EVALU)
  ## MER = MeritSimulator(seed=SEED_EVALU)
  thetasNon = []; thetasNon.append(Worst_theta_Alloc)
  ## thetasNon = []; thetasNon.append(
  ##   Policy(None).build_theta(
  ##     {'thCumShifts': 1.0, 'thSickProb': 1.0}
  ##   )
  ## )
  # ThetaStar_expCbarcum_Alloc_evalu_non, ThetaStar_expCtilcum_Alloc_evalu_non, \
  # _, _, \
  # Best_theta_Alloc_evalu_non, Worst_theta_Alloc_evalu_non, \
  # _, _, \
  # _, _, \
  # Record_Alloc_evalu_non = \
  #   P.perform_grid_search_sample_paths('X__Alloc', thetasNon, L, T)
  return \
    P.perform_grid_search_sample_paths('X__Alloc', thetasNon, L, T)
    
  # Df_Alloc_evalu_non = pd.DataFrame.from_records(
  #     Record_Alloc_evalu_non[:First_n_t], columns=Labels)
  # print(f'{ThetaStar_expCbarcum_Alloc_evalu_non.iloc[-1]=:.2f}')
